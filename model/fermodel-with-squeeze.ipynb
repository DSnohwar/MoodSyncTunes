{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('default')\n\nimport os\nimport tensorflow as tf\nimport keras\nimport cv2\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPool2D,BatchNormalization, LSTM,MaxPooling2D\nfrom keras.models import Sequential\nfrom keras import regularizers\nimport keras\n\nfrom keras.layers import TimeDistributed\nfrom keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.applications import MobileNetV2\n\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:14.801576Z","iopub.execute_input":"2023-11-26T13:26:14.802494Z","iopub.status.idle":"2023-11-26T13:26:14.810865Z","shell.execute_reply.started":"2023-11-26T13:26:14.802452Z","shell.execute_reply":"2023-11-26T13:26:14.810023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fer2013/train/'\ntest_dir = '/kaggle/input/fer2013/test/'\nprint(os.listdir(train_dir))\nprint(os.listdir(test_dir))","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:15.317748Z","iopub.execute_input":"2023-11-26T13:26:15.318038Z","iopub.status.idle":"2023-11-26T13:26:15.334326Z","shell.execute_reply.started":"2023-11-26T13:26:15.318013Z","shell.execute_reply":"2023-11-26T13:26:15.333484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Classes_Count( path, name):\n    Classes_Dict = {}\n    \n    for Class in os.listdir(path):\n        \n        Full_Path = path + Class\n        Classes_Dict[Class] = len(os.listdir(Full_Path))\n        \n    df = pd.DataFrame(Classes_Dict, index=[name])\n    \n    return df\n\nTrain_Count = Classes_Count(train_dir, 'Train').transpose().sort_values(by=\"Train\", ascending=False)\nTest_Count = Classes_Count(test_dir, 'Test').transpose().sort_values(by=\"Test\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:17.547072Z","iopub.execute_input":"2023-11-26T13:26:17.547713Z","iopub.status.idle":"2023-11-26T13:26:17.575582Z","shell.execute_reply.started":"2023-11-26T13:26:17.547671Z","shell.execute_reply":"2023-11-26T13:26:17.574703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat([Train_Count,Test_Count] , axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:18.375396Z","iopub.execute_input":"2023-11-26T13:26:18.376150Z","iopub.status.idle":"2023-11-26T13:26:18.385394Z","shell.execute_reply.started":"2023-11-26T13:26:18.376121Z","shell.execute_reply":"2023-11-26T13:26:18.384502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6),dpi=150)\nsns.barplot(x=Train_Count.index, y='Train', data=Train_Count)\nplt.title('Train Values per Emotion Category')\nplt.xlabel('Emotion')\nplt.ylabel('Training image Count')","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:18.560077Z","iopub.execute_input":"2023-11-26T13:26:18.560350Z","iopub.status.idle":"2023-11-26T13:26:18.924142Z","shell.execute_reply.started":"2023-11-26T13:26:18.560326Z","shell.execute_reply":"2023-11-26T13:26:18.923340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6),dpi=150)\nsns.barplot(x=Test_Count.index, y='Test', data=Test_Count)\nplt.title('Test Values per Emotion Category')\nplt.xlabel('Emotion')\nplt.ylabel('Testing image Count')","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:21.415178Z","iopub.execute_input":"2023-11-26T13:26:21.415968Z","iopub.status.idle":"2023-11-26T13:26:21.802490Z","shell.execute_reply.started":"2023-11-26T13:26:21.415932Z","shell.execute_reply":"2023-11-26T13:26:21.801585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('default')\nplt.figure(figsize = (25, 8))\nimage_count = 1\nBASE_URL = '/kaggle/input/fer2013/train/'\n\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(1, 7, image_count)\n                image_count += 1\n                image = cv2.imread(BASE_URL + directory + '/' + file)\n                image_shape = image.shape\n                print(\"Image Shape:\", image_shape)\n                plt.imshow(image)\n                plt.title(directory, fontsize = 20)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:21.804409Z","iopub.execute_input":"2023-11-26T13:26:21.804796Z","iopub.status.idle":"2023-11-26T13:26:23.057307Z","shell.execute_reply.started":"2023-11-26T13:26:21.804763Z","shell.execute_reply":"2023-11-26T13:26:23.056393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = 48\nbatch_size = 128\ntrain_data_path = '/kaggle/input/fer2013/train'\ntest_data_path = '/kaggle/input/fer2013/test'","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:23.164263Z","iopub.execute_input":"2023-11-26T13:26:23.164550Z","iopub.status.idle":"2023-11-26T13:26:23.169802Z","shell.execute_reply.started":"2023-11-26T13:26:23.164526Z","shell.execute_reply":"2023-11-26T13:26:23.168915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessor = ImageDataGenerator(\n        rescale = 1 / 255.,\n        # Data Augmentation\n        rotation_range=10,\n        zoom_range=0.2,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,                                        \n        fill_mode='nearest',\n    )\n\n\ntest_preprocessor = ImageDataGenerator(\n    rescale = 1 / 255.,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:23.415141Z","iopub.execute_input":"2023-11-26T13:26:23.415417Z","iopub.status.idle":"2023-11-26T13:26:23.420501Z","shell.execute_reply.started":"2023-11-26T13:26:23.415392Z","shell.execute_reply":"2023-11-26T13:26:23.419559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_preprocessor.flow_from_directory(\n    train_data_path,\n    class_mode=\"categorical\",\n    target_size=(img_shape,img_shape),\n    color_mode='grayscale', \n    shuffle=True,\n    batch_size=batch_size,\n    subset='training', \n)\n\n\ntest_data = test_preprocessor.flow_from_directory(\n    test_data_path,\n    class_mode=\"categorical\",\n    target_size=(img_shape,img_shape),\n    color_mode='grayscale',\n    shuffle=False,\n    batch_size=batch_size,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:25.088639Z","iopub.execute_input":"2023-11-26T13:26:25.088980Z","iopub.status.idle":"2023-11-26T13:26:31.063147Z","shell.execute_reply.started":"2023-11-26T13:26:25.088955Z","shell.execute_reply":"2023-11-26T13:26:31.062305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SqueezeExciteBlock(tf.keras.layers.Layer):\n    def __init__(self, units, ratio=16):\n        super(SqueezeExciteBlock, self).__init__()\n        self.units = units\n        self.ratio = ratio\n\n    def build(self, input_shape):\n        num_channels = input_shape[-1]\n        \n        self.squeeze = tf.keras.layers.GlobalAveragePooling2D()\n        self.excitation = tf.keras.Sequential([\n            tf.keras.layers.Dense(num_channels // self.ratio, activation='relu'),\n            tf.keras.layers.Dense(num_channels, activation='sigmoid'),\n        ])\n        self.reshape = tf.keras.layers.Reshape((1, 1, num_channels))\n\n    def call(self, inputs):\n        squeezed = self.squeeze(inputs)\n        excited = self.excitation(squeezed)\n        excited = self.reshape(excited)\n        scaled_input = tf.keras.layers.Multiply()([inputs, excited])\n        return scaled_input","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:31.065199Z","iopub.execute_input":"2023-11-26T13:26:31.065884Z","iopub.status.idle":"2023-11-26T13:26:31.073810Z","shell.execute_reply.started":"2023-11-26T13:26:31.065848Z","shell.execute_reply":"2023-11-26T13:26:31.072828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Create_CNN_Model():\n    model = Sequential()\n\n    # CNN1\n    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_shape, img_shape, 1)))\n    model.add(BatchNormalization())\n    \n    # Add Squeeze-and-Excitation after CNN1\n    model.add(SqueezeExciteBlock(64))\n\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(Dropout(0.25))\n\n    # CNN2\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n\n    # Add Squeeze-and-Excitation after CNN2\n    model.add(SqueezeExciteBlock(128))\n\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(Dropout(0.25))\n\n    # CNN3\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(BatchNormalization())\n\n    # Add Squeeze-and-Excitation after CNN3\n    model.add(SqueezeExciteBlock(256))\n\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(Dropout(0.25))\n    \n    model.add(SqueezeExciteBlock(256))\n\n    # Global Average Pooling\n    model.add(GlobalAveragePooling2D())\n\n    # Fully Connected Layers\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(7, activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:31.074918Z","iopub.execute_input":"2023-11-26T13:26:31.075221Z","iopub.status.idle":"2023-11-26T13:26:31.087578Z","shell.execute_reply.started":"2023-11-26T13:26:31.075195Z","shell.execute_reply":"2023-11-26T13:26:31.086713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Model = Create_CNN_Model()\n\nCNN_Model.summary()\n\nCNN_Model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy']) #Lr=0.001","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:26:31.089036Z","iopub.execute_input":"2023-11-26T13:26:31.089277Z","iopub.status.idle":"2023-11-26T13:26:31.579130Z","shell.execute_reply.started":"2023-11-26T13:26:31.089256Z","shell.execute_reply":"2023-11-26T13:26:31.578318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callback Checkpoint\ncheckpoint_path = \"CNN_Model_With_Squeeze_Checkpoint.tf\"\n\nCheckpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True,mode='max',verbose=1)\n\n# Early Stopping Callback to monitor the accuracy\nEarly_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True, verbose=1)\n\n# ReduceLROnPlateau Callback to reduce overfitting by decreasing learning rate\nReducing_LR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=2,\n    min_lr=0.000005,\n    verbose=1\n)\n\n\ncallbacks = [Early_Stopping, Reducing_LR]\n\nsteps_per_epoch = train_data.n // train_data.batch_size\nvalidation_steps = test_data.n // test_data.batch_size","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:27:18.377011Z","iopub.execute_input":"2023-11-26T13:27:18.377728Z","iopub.status.idle":"2023-11-26T13:27:18.384024Z","shell.execute_reply.started":"2023-11-26T13:27:18.377694Z","shell.execute_reply":"2023-11-26T13:27:18.383087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_history = CNN_Model.fit( train_data , validation_data= test_data , epochs=50, batch_size= batch_size,\n                            callbacks=callbacks, steps_per_epoch= steps_per_epoch, validation_steps=validation_steps)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist=CNN_history.history\nplt.plot(hist[\"accuracy\"])\nplt.plot(hist[\"val_accuracy\"])\nplt.title(\"Accuracy plot\")\nplt.legend([\"train\",\"test\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.savefig(\"CNNv2_accuracy.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist[\"loss\"])\nplt.plot(hist[\"val_loss\"])\nplt.title(\"Accuracy loss\")\nplt.legend([\"train\",\"test\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.savefig(\"CNNv2_loss.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the entire model (architecture + weights)\nimport datetime\n\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\nmodel_filename = f\"/kaggle/working/CNN_Modelv3Sq_{timestamp}.tf\"\nmodel_weightsfilename = f\"/kaggle/working/CNN_Weights_Modelv3Sq_{timestamp}.tf\"\n\nCNN_Model.save(model_filename)\nCNN_Model.save_weights(model_weightsfilename)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}